#!/usr/bin/env python

'''readhatlc.py - Waqas Bhatti (wbhatti@astro.princeton.edu) - Jan 2014

Contains functions to read HAT LCs generated by the HAT LC server.

read_hatlc(hatlc) --> Read a retrieved HAT LC into a dict

'''

import os.path
import subprocess
import shlex

import numpy as np
import astropy.io.fits as pyfits

#########################
## SETTINGS AND CONFIG ##
#########################

TEXTLC_OUTPUT_COLUMNS = {
    'BJD':['time in Baryocentric Julian Date',
           '%20.7f','D',float],
    'MJD':['time in Modified Julian Date',
           '%20.7f','D',float],
    'HJD':['time in Heliocentric Julian Date',
           '%20.7f','D',float],
    'RJD':['time in Reduced Julian Date',
           '%20.7f','D',float],
    'FJD':['time in Full Julian Date',
           '%20.7f','D',float],
    'XCC':['x coordinate on CCD',
           '%.1f','E',float],
    'YCC':['y coordinate on CCD',
           '%.1f','E',float],
    'IM1':['instrumental lightcurve magnitude (aperture 1)',
           '%12.5f','D',float],
    'IE1':['instrumental lightcurve measurement error (aperture 1)',
           '%12.5f','D',float],
    'IQ1':['instrumental lightcurve quality flag (aperture 1)',
           '%s','1A',str],
    'IM2':['instrumental lightcurve magnitude (aperture 2)',
           '%12.5f','D',float],
    'IE2':['instrumental lightcurve measurement error (aperture 2)',
           '%12.5f','D',float],
    'IQ2':['instrumental lightcurve quality flag (aperture 2)',
           '%s','1A',str],
    'IM3':['instrumental lightcurve magnitude (aperture 3)',
           '%12.5f','D',float],
    'IE3':['instrumental lightcurve measurement error (aperture 3)',
           '%12.5f','D',float],
    'IQ3':['instrumental lightcurve quality flag (aperture 3)',
           '%s','1A',str],
    'RM1':['reduced lightcurve magnitude (aperture 1)',
           '%12.5f','D',float],
    'RM2':['reduced lightcurve magnitude (aperture 2)',
           '%12.5f','D',float],
    'RM3':['reduced lightcurve magnitude (aperture 3)',
           '%12.5f','D',float],
    'EP1':['EPD lightcurve magnitude (aperture 1)',
           '%12.5f','D',float],
    'EP2':['EPD lightcurve magnitude (aperture 2)',
           '%12.5f','D',float],
    'EP3':['EPD lightcurve magnitude (aperture 3)',
           '%12.5f','D',float],
    'TF1':['TFA lightcurve magnitude (aperture 1)',
           '%12.5f','D',float],
    'TF2':['TFA lightcurve magnitude (aperture 2)',
           '%12.5f','D',float],
    'TF3':['TFA lightcurve magnitude (aperture 3)',
           '%12.5f','D',float],
    'RSTF':['HAT station and frame number of this LC point',
            '%s','10A',str],
    'RSTFC':['HAT station, frame number, and CCD of this LC point',
             '%s','10A',str],
    'ESTF':['HAT station and frame number of this LC point',
            '%s','10A',str],
    'ESTFC':['HAT station, frame number, and CCD of this LC point',
             '%s','10A',str],
    'TSTF':['HAT station and frame number of this LC point',
            '%s','10A',str],
    'TSTFC':['HAT station, frame number, and CCD of this LC point',
             '%s','10A',str],
    'FSV':['PSF fit S value',
           '%12.5f','E',float],
    'FDV':['PSF fit D value',
           '%12.5f','E',float],
    'FKV':['PSF fit K value',
           '%12.5f','E',float],
    'FLT':['filter used for this LC point',
           '%s','1A',str],
    'FLD':['observed HAT field',
           '%s','15A',str],
    'CCD':['CCD taking this LC point ',
           '%s','I',int],
    'CFN':['CCD frame number',
           '%s','I',int],
    'STF':['HAT station taking this LC point',
           '%s','I',int],
    'BGV':['Background value',
           '%12.5f','E',float],
    'BGE':['Background error',
           '%12.5f','E',float],
    'IHA':['Hour angle of object [hr]',
           '%12.5f','E',float],
    'IZD':['Zenith distance of object [deg]',
           '%12.5f','E',float],
    'NET':['HAT network responsible for this LC point',
           '%s','2A',str],
    'EXP':['exposure time for this LC point [seconds]',
           '%12.3f','E',float],
    'CAM':['camera taking the exposure for this LC point',
           '%s','2A',str],
    'TEL':['telescope taking the exposure for this LC point',
           '%s','2A',str],
    }



#######################
## UTILITY FUNCTIONS ##
#######################

def compress_lcfile(lcfilepath, method='gz'):
    '''
    This compresses the lightcurve using the method specified.

    method = 'gz', 'bz2'

    '''

    zip_cmds = {'gz':'gzip -f %s' % lcfilepath,
                'bz2':'bzip2 -f %s' % lcfilepath}

    outfile = lcfilepath + '.' + method

    proccmd = shlex.split(zip_cmds[method])

    try:
        retcode = subprocess.check_call(proccmd)
        return outfile
    except subprocess.CalledProcessError:
        return None


def decompress_lcfile(lcfilepath):
    '''
    This decompresses the lightcurve.

    '''

    unzip_cmds = {'gz':'gunzip %s' % lcfilepath,
                  'bz2':'bunzip2 %s' % lcfilepath}

    if '.bz2' in lcfilepath:
        outfile = lcfilepath.strip('.bz2')
        method = 'bz2'
    elif '.gz' in lcfilepath:
        outfile = lcfilepath.strip('.gz')
        method = 'gz'

    proccmd = shlex.split(unzip_cmds[method])

    try:
        retcode = subprocess.check_call(proccmd)
        return outfile
    except subprocess.CalledProcessError:
        return None



##############################
## READING RETRIEVED HATLCS ##
##############################

def read_hatlc(hatlc):
    '''
    This reads a HAT LC file (any format) generated by the HAT LC server.

    Returns a dict with the following keys always present:

    'hatid': HAT ID of the object
    'twomassid': 2MASS ID of the object
    'ra': RA (J2000 deg) of the object
    'dec': DEC (J2000 deg) of the object
    'mags': V, R, I, J, H, K magnitudes of the object
    'hatstations': HATs used for this object
    'ndet': number of detections of this object
    'filters': camera filters used for this object
    'cols': a list of columns present in this lightcurve

    The rest of the keys are column names as requested and defined in
    TEXTLC_OUTPUT_COLUMNS above.

    '''

    lcfname = os.path.basename(hatlc)

    if '.fits' in lcfname:

        # unzip the files if we have to
        if '.gz' in lcfname or '.bz2' in lcfname:
            lcfpath = decompress_lcfile(hatlc)
        else:
            lcfpath = hatlc

        if lcfpath:

            hdulist = pyfits.open(lcfpath)
            objectinfo = hdulist[0].header
            objectlc = hdulist[1].data
            lccols = objectlc.columns.names
            hdulist.close()

            if '.gz' in lcfname or '.bz2' in lcfname:
                # recompress the uncompressed file
                recompressed_lcfile = compress_lcfile(lcfpath)
                assert hatlc == recompressed_lcfile

            lcdict = {}

            for col in lccols:
                lcdict[col] = np.array(objectlc[col])

            lcdict['hatid'] = objectinfo['hatid']
            lcdict['twomassid'] = objectinfo['2massid']
            lcdict['ra'] = objectinfo['ra']
            lcdict['dec'] = objectinfo['dec']
            lcdict['mags'] = [objectinfo[x] for x in ('vmag','rmag','imag',
                                                      'jmag','hmag','kmag')]
            lcdict['ndet'] = objectinfo['ndet']
            lcdict['hatstations'] = objectinfo['hats']
            lcdict['filters'] = objectinfo['filters']
            lcdict['columns'] = lccols

            return lcdict

        else:

            return None

    elif '.csv' in lcfname or '.hatlc' in lcfname:

        # unzip the files if we have to
        if '.gz' in lcfname or '.bz2' in lcfname:
            lcfpath = decompress_lcfile(hatlc)
        else:
            lcfpath = hatlc

        if lcfpath:

            lcf = open(lcfpath,'r')
            lcflines = lcf.readlines()
            lcf.close()

            # recompress the uncompressed file
            recompressed_lcfile = compress_lcfile(lcfpath)
            assert hatlc == recompressed_lcfile

            # now process the read-in LC
            objectdata = [x for x in lcflines if x.startswith('#')]
            objectlc = [x for x in lcflines if not x.startswith('#')]
            objectlc = [x for x in objectlc if len(x) > 1]

            if '.csv' in lcfpath:
                objectlc = [x.split(',') for x in objectlc]
            else:
                objectlc = [x.split() for x in objectlc]

            # transpose split rows to get columns
            objectlc = zip(*objectlc)

            # read the header to figure out the object's info and column names
            objectdata = [x.strip('#') for x in objectdata]
            objectdata = [x.strip() for x in objectdata]
            objectdata = [x for x in objectdata if len(x) > 0]

            hatid, twomassid = objectdata[0].split(' - ')
            ra, dec = objectdata[1].split(', ')
            ra = float(ra.split(' = ')[-1].strip(' deg'))
            dec = float(dec.split(' = ')[-1].strip(' deg'))

            vmag, rmag, imag, jmag, hmag, kmag = objectdata[2].split(', ')
            vmag = float(vmag.split(' = ')[-1])
            rmag = float(rmag.split(' = ')[-1])
            imag = float(imag.split(' = ')[-1])
            jmag = float(jmag.split(' = ')[-1])
            hmag = float(hmag.split(' = ')[-1])
            kmag = float(kmag.split(' = ')[-1])

            ndet = int(objectdata[3].split(': ')[-1])
            hatstations = objectdata[4].split(': ')[-1]

            filterhead_ind = objectdata.index('Filters used:')
            columnhead_ind = objectdata.index('Columns:')

            filters = objectdata[filterhead_ind:columnhead_ind]

            columndefs = objectdata[columnhead_ind+1:]

            columns = []
            for line in columndefs:

                colnum, colname, coldesc = line.split(' - ')
                columns.append(colname)

            lcdict = {}

            # now write all the columns to the output dictionary
            new_columns = []
            for col in columns:
                #if col not in TEXTLC_OUTPUT_COLUMNS:
                    #print col
                if col in TEXTLC_OUTPUT_COLUMNS:
                    new_columns.append(col)
            columns = []
            for col in new_columns: columns.append(col)

            for ind, col in enumerate(columns):

                # this formats everything nicely using our existing column
                # definitions
                lcdict[col] = np.array([TEXTLC_OUTPUT_COLUMNS[col][3](x)
                                        for x in objectlc[ind]])

            # write the object metadata to the output dictionary
            lcdict['hatid'] = hatid
            lcdict['twomassid'] = twomassid.strip('2MASS J')
            lcdict['ra'] = ra
            lcdict['dec'] = dec
            lcdict['mags'] = [vmag, rmag, imag, jmag, hmag, kmag]
            lcdict['ndet'] = ndet
            lcdict['hatstations'] = hatstations.split(', ')
            lcdict['filters'] = filters[1:]
            lcdict['cols'] = columns

            return lcdict

        else:

            return None
